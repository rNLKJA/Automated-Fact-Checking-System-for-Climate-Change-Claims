{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61e464-4ba2-495e-bd78-273d0c28749c",
   "metadata": {},
   "source": [
    "# Data Preprocessing Dev\n",
    "\n",
    "1. **Load and Preprocess Evidence Data**:\n",
    "\n",
    "- *Data Structure*: Your dataset, evidence_df, contains two columns: evidence_id and evidence_paragraph.\n",
    "- *Objective*: Use all evidence paragraphs to train a TF-IDF model. This model will be used to retrieve the most relevant evidences for a given input claim.\n",
    "\n",
    "2. **TF-IDF for Evidence Retrieval**:\n",
    "\n",
    "- *Preprocessing*: Clean and preprocess the evidence paragraphs to optimize them for TF-IDF vectorization (e.g., removing stopwords, punctuation, and normalizing text).\n",
    "- *Vectorization*: Apply TF-IDF vectorization to the preprocessed evidence paragraphs to create a matrix representing the importance of terms in each document.\n",
    "- *Similarity Calculation*: When a new claim is received, convert it into a TF-IDF vector using the same vectorizer and calculate its cosine similarity against the TF-IDF matrix to find the most relevant evidences.\n",
    "\n",
    "3. **Construct an Evidence List**:\n",
    "\n",
    "*Relevance*: Based on the similarity scores, select the top relevant evidences. This list will be used for further processing and classification.\n",
    "\n",
    "4. **Concatenate Claim and Evidences**:\n",
    "\n",
    "*Integration*: Concatenate the input claim with its corresponding top relevant evidences into a single text block (paragraph). This concatenated text serves as a comprehensive context for the claim.\n",
    "\n",
    "5. **Word2Vec Model Training and Application**:\n",
    "\n",
    "- *Model Building*: Build a Word2Vec model from scratch using PyTorch to learn word embeddings from the concatenated text of claims and their relevant evidences.\n",
    "- *Usage*: The trained Word2Vec model can be used to convert words or phrases from the claims and evidences into vectors, which can then be utilized for various tasks such as classification, clustering, or further similarity measurements.\n",
    "\n",
    "6. **Classification**:\n",
    "\n",
    "- *Approach*: Use the embeddings from the Word2Vec model along with additional features (if necessary) to classify the claim into one of four predefined categories.\n",
    "- *Model Selection*: Depending on the complexity and nature of the classification, choose an appropriate machine learning or deep learning model. This could be a simple logistic regression, a support vector machine, or a more complex neural network.\n",
    "\n",
    "**Considerations for Implementation**:\n",
    "- *Modularity*: Each step should be encapsulated within its class or function to ensure modularity and ease of maintenance.\n",
    "- *Scalability*: Design the system to handle increases in data volume efficiently, possibly by optimizing data handling and processing.\n",
    "- *Extensibility*: Allow for easy updates and modifications, such as adding new preprocessing steps, changing the classification model, or adjusting the number of top evidences retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49d6cc-043e-4415-819e-48545d8a2fdd",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Evidence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9716d4e-be2d-4b9f-a10e-0ceaa4d98265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, file_path: Union[str, Path]):\n",
    "        \"\"\"\n",
    "        Initializes the DataLoader with the path to the dataset.\n",
    "        :param file_path: str, path to the dataset in JSON format.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the data from the specified JSON file path.\n",
    "        :return: DataFrame, the loaded data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_json(self.file_path)\n",
    "            print(\"Data loaded successfully.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading the data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1185c08-5aab-405c-85ec-fb59695c2d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b032bfd-4985-40e9-83f4-27fe72ca4bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6ab77-0ab8-48d1-a47c-469f960ea20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24bdb7-ffd8-4f9c-9fe7-8fb81f68d70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ff3ae-95f7-49bb-8cff-c7c710cd7361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b1004-bd48-49d7-abe4-1d4323ca5066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4893e68-9af7-48c0-b5e7-503a321c9b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81aca48-b500-45f7-b7b6-ae9482d1f17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65ac82-3a3a-4134-adaf-9d7d21faa4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508d3ca-63fe-4a04-8ecc-ebadd790cb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8.19",
   "language": "python",
   "name": "python3.8.19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
